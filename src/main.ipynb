{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import gym\n",
    "from gym import spaces\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = [\"AAPL\", \"AMZN\", \"GOOGL\", \"MSFT\", \"NVDA\", \"TSLA\"]\n",
    "\n",
    "data = {i: {t: float(row[t]) for t in tickers} \\\n",
    "    for i, row in enumerate(csv.DictReader( \\\n",
    "    open(\"nasdaq_stock_prices.csv\", mode='r'), delimiter=','))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment(gym.Env):\n",
    "    def __init__(self, data: dict, window_size: int, initial_balance: float):\n",
    "        self.current_step = 0\n",
    "        self.history_prices = data\n",
    "        self.current_prices = self.history_prices[self.current_step]\n",
    "        self.max_steps = len(data) - 1\n",
    "        self.tickers = list(data[0].keys())\n",
    "        self.window_size = window_size\n",
    "\n",
    "        self.initial_balance = initial_balance\n",
    "        self.history_balance = {0: self.initial_balance}\n",
    "        self.current_balance = self.history_balance[self.current_step]\n",
    "\n",
    "        self.initial_shares = {t: 0 for t in self.tickers}\n",
    "        self.history_shares = {0: self.initial_shares}\n",
    "        self.current_shares = self.history_shares[self.current_step]\n",
    "\n",
    "        self.initial_value = 0\n",
    "        self.history_value = {0: self.initial_value}\n",
    "        self.current_value = self.history_value[self.current_step]\n",
    "\n",
    "        self.action_space = spaces.Box(low = -1.0, high = 1.0, shape = (len(self.tickers),))\n",
    "    \n",
    "        self.observation_dimension = len(self.tickers) * (self.window_size + 1) + 2  #window of prices (n*w) + current_shares (n) + current_balance (1) + current_value (1)\n",
    "        self.observation_space = spaces.Box(low = -np.inf, high = np.inf, shape = (self.observation_dimension,))\n",
    "\n",
    "        self.done = False\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_step = 0\n",
    "        self.history_balance = {0: self.initial_balance}\n",
    "        self.current_balance = self.initial_balance\n",
    "        self.history_shares = {0: self.initial_shares}\n",
    "        self.current_shares = self.initial_shares\n",
    "        self.history_value = {0: self.initial_value}\n",
    "        self.current_value = self.initial_value\n",
    "        self.done = False\n",
    "        return self._get_state()\n",
    "    \n",
    "    def render(self):\n",
    "        return self.history_balance, self.history_shares, self.history_value\n",
    "    \n",
    "    def _get_state(self):\n",
    "        start = max(0, self.current_step - self.window_size)\n",
    "        end = self.current_step + 1\n",
    "        return self.history_prices[start, end], self.history_balance[start, end], self.history_shares[start, end], self.history_value[start, end]\n",
    "    \n",
    "    def step(self, action: np.ndarray):\n",
    "        if self.done:\n",
    "            return self._get_state(), 0, self.done, {}\n",
    "\n",
    "        if np.sum(action) > 1.0:\n",
    "            raise ValueError(f\"Invalid action: total buy fraction = {np.sum(action):.2f} > 1.0\")\n",
    "        \n",
    "        if any([a < -1.0 for a in action]):\n",
    "            raise ValueError(f\"Invalid action: sell fraction < -1.0\")\n",
    "\n",
    "        for i, ticker in enumerate(self.tickers):\n",
    "            act = action[i]\n",
    "            if act < 0:\n",
    "                shares_to_sell = self.current_shares[ticker] * (-act)\n",
    "                proceeds = shares_to_sell * self.current_prices[ticker]\n",
    "                self.current_balance += proceeds\n",
    "                self.current_shares[ticker] -= shares_to_sell\n",
    "\n",
    "            elif act > 0:\n",
    "                amount_to_invest = self.current_balance * act\n",
    "                shares_to_buy = amount_to_invest / self.current_prices[ticker]\n",
    "                cost = shares_to_buy * self.current_prices[ticker]\n",
    "                self.current_balance -= cost\n",
    "                self.current_shares[ticker] += shares_to_buy\n",
    "\n",
    "        self.current_value = self.current_balance + sum(self.current_shares[t] * self.current_prices[t] for t in self.tickers)\n",
    "\n",
    "        self.current_step += 1\n",
    "        self.done = self.current_step >= self.max_steps\n",
    "\n",
    "        self.history_balance[self.current_step] = self.current_balance\n",
    "        self.history_shares[self.current_step] = self.current_shares.copy()\n",
    "        self.history_value[self.current_step] = self.current_value\n",
    "\n",
    "        reward = self.current_value - self.initial_value\n",
    "\n",
    "        return self._get_state(), reward, self.done, {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment = Environment(data, 10, initial_balance=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "(0, 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m environment\u001b[38;5;241m.\u001b[39mrender()\n\u001b[0;32m----> 2\u001b[0m \u001b[43menvironment\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[39], line 91\u001b[0m, in \u001b[0;36mEnvironment.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhistory_profit[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_step] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_profit\n\u001b[1;32m     89\u001b[0m reward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_profit\n\u001b[0;32m---> 91\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, reward, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone, {}\n",
      "Cell \u001b[0;32mIn[39], line 46\u001b[0m, in \u001b[0;36mEnvironment._get_state\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     44\u001b[0m start \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwindow_size)\n\u001b[1;32m     45\u001b[0m end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_step \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 46\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhistory_prices\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m]\u001b[49m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhistory_balance[start, end], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhistory_shares[start, end], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhistory_profit[start, end]\n",
      "\u001b[0;31mKeyError\u001b[0m: (0, 2)"
     ]
    }
   ],
   "source": [
    "environment.render()\n",
    "environment.step(np.array([0.1, 0.1, 0.1, 0.1, 0.1, 0.1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent: #To be defined\n",
    "    def __init__(self, env):\n",
    "        self.env = env\n",
    "\n",
    "    def train(self):\n",
    "        pass\n",
    "\n",
    "    def test(self):\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virtenv-rl-course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
